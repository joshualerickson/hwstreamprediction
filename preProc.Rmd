---
title: "FFS RF without 3rd and 4th Orders"
author: "Josh Erickson"
date: "April 14, 2020"
output: html_document
---

```{r setup, include=FALSE}

library(sf)
library(raster)
library(caret)
library(CAST)
library(blockCV)
library(nhdplusTools)
library(corrplot)
library(tidyverse)
```

Now bring in all the TIFs to be used in the anlaysis and stack/visualise.
```{r, eval=FALSE}
library(raster)


twi30 <- raster("D:/Rcodes/Water_Prediction/Hird_Water_Prediction/waterD/waterPred/Final_Workflow/twi30agg.tif") #TWI

vvsd30 <- raster("D:/Rcodes/Water_Prediction/Hird_Water_Prediction/waterD/waterPred/Final_Workflow/vvsd30agg.tif") #vertical vertical sd

vv30 <- raster("D:/Rcodes/Water_Prediction/Hird_Water_Prediction/waterD/waterPred/Final_Workflow/vv30agg.tif") #vertical vertical mean

npol30 <- raster("D:/Rcodes/Water_Prediction/Hird_Water_Prediction/waterD/waterPred/Final_Workflow/npol30agg.tif") #normalized polarization 

accum30 <- raster("D:/Rcodes/Water_Prediction/Hird_Water_Prediction/waterD/waterPred/Final_Workflow/accum30.tif") #UAA d-infinity aggregated from 10-m

nppMid30 <- raster("D:/Rcodes/Water_Prediction/Hird_Water_Prediction/waterD/waterPred/Final_Workflow/nppmmid30agg.tif") #NPP median '86-18'

deficit <- raster("D:/Rcodes/Water_Prediction/Hird_Water_Prediction/waterD/waterPred/Final_Workflow/deficitRS.tif") # annual CWD 30 yr

wtrbdy30 <- raster("D:/Rcodes/Water_Prediction/Hird_Water_Prediction/waterD/waterPred/Final_Workflow/wtrbdy30agg.tif") #waterbodies

tpi30 <- raster("D:/Rcodes/Water_Prediction/Hird_Water_Prediction/waterD/waterPred/Final_Workflow/tpi30agg.tif") #TPI

CAD <- raster("D:/Rcodes/Water_Prediction/Hird_Water_Prediction/waterD/waterPred/Final_Workflow/cad30RS.tif") #cold air drainage

decid <- raster("D:/Rcodes/Water_Prediction/Hird_Water_Prediction/waterD/waterPred/Final_Workflow/decid30RS.tif") #deciduous

Blue <- raster("Blue_med.tif") #blue (B2)

Green <- raster("Green_med.tif") #green (B3)

Red <- raster("Red_med.tif") #red (B4)

NIR <- raster("NIR_med.tif") #Near Infrared (B8)

NDVI <-  raster("NDVI_med.tif")
  
NDWI <-  raster("NDWI_med.tif")

cpgPrecip <- raster("D:/Rcodes/Water_Prediction/Hird_Water_Prediction/waterD/waterPred/Final_Workflow/cpg30precip.tif") #Continuous parameter grid (precipitation/PRISM).


topo_opt_rad34 <- stack(twi30, tpi30, accum30,vv30, vvsd30, npol30,  NDVI, NDWI, nppMid30, deficit, CAD, decid, Blue, Green, Red, NIR, cpgPrecip)
```

Now visualise.

```{r, echo=FALSE}

plot(topo_opt_rad34, maxnl=32, nc = 4, legend = FALSE)

```


Bring in the points collected in the field.

```{r, eval=FALSE}

#combine point objects
proj.study <- "+proj=aea +lat_1=46 +lat_2=48 +lat_0=44 +lon_0=-109.5 +x_0=600000 +y_0=0 +datum=NAD83 +units=m +no_defs +ellps=GRS80 +towgs84=0,0,0"

pts34 <- read_sf("D:/Rcodes/Water_Prediction/Hird_Water_Prediction/waterD/waterPred/Final_workflow/points_spaced30m.shp")  #points to the folder/feature

st_crs(pts34) <- proj.study

pts34 <- st_transform(pts34, crs = proj.study)

#clean up

pts34 <- pts34[,c(2)]

```


Now bring in the applicable polygons for clipping, etc.
```{r, eval=FALSE}
lands_folder <- "D:/documents/Documents/Josh/Documents/GIS/District_H20_exports/Lands_District_stuff"

#Get forest service boundary
FSland <- read_sf(paste0(lands_folder, "/knf_ownership.shp"))
FSland <- FSland[FSland$OWNER == 'FS',]

FSland <- st_transform(FSland, proj.study)

#Get District Boundary
DistrictBoundary <- read_sf(paste0(lands_folder, "/fortine_rexford_RD_Bdy.shp"))[1]

DistrictBoundary <- st_transform(DistrictBoundary, proj.study)
#now intersect
landClip <- st_intersection(FSland, DistrictBoundary)

#read in the landClip we created and call it FSland
FSland <- landClip

plot(FSland)

##st_write(landClip, 'hw_study.gpkg', "LandClip", driver = "ESRI Shapefile", update = TRUE)
##st_write(DistrictBoundary, 'hw_study.gpkg', "DistrictBoundary", driver = "ESRI Shapefile")
```

Now we'll need to bring in the NHDPlus layer and then rasterize so that we can get NHDPlus baseline data. Better to do now then latter.

```{r, eval=FALSE}

##download_dir <- download_nhdplushr(nhd_dir = getwd(), c("1701"))

nhdPlushr <- get_nhdplushr(getwd(), "nhdplus.gpkg",
layers = "NHDFlowline", overwrite = TRUE, proj = "+proj=aea +lat_1=46 +lat_2=48 +lat_0=44 +lon_0=-109.5 +x_0=600000 +y_0=0 +datum=NAD83 +units=m +no_defs +ellps=GRS80 +towgs84=0,0,0")

nhdDistrict <- nhdPlushr$NHDFlowline

nhdDistrict <- st_transform(nhdDistrict, "+proj=aea +lat_1=46 +lat_2=48 +lat_0=44 +lon_0=-109.5 +x_0=600000 +y_0=0 +datum=NAD83 +units=m +no_defs +ellps=GRS80 +towgs84=0,0,0")

nhdDistrict <- st_crop(nhdDistrict, c(xmin = 150035.8, xmax = 222365.8, 
                                      ymin = 507390, ymax = 574500 ))

plot(nhdDistrict["StreamOrde"], main = "NHDPlus High Res with Stream Order")

nhdDistrictSF <- st_as_sf(nhdDistrict)
st_write(nhdDistrictSF, "hw_study.gpkg", "nhdDistrictSF")
```

This just reads in the data we created from above and rasterizes it.

```{r, eval = FALSE}
nhdDistrictSF <- st_read("hw_study.gpkg", "nhdDistrictSF")
#now make a 30m raster with streamorder

ndhStrOrdRast <- rasterize(nhdDistrict, tpi30, field = "StreamOrde")

writeRaster(ndhStrOrdRast, "nhdStrOrdRast.tiff", overwrite = TRUE)

nhdStrOrdRast <- raster("nhdStrOrdRast.tif")

```

Now check some stats for the sample area real quick.

```{r}
#sample space area sq/km
area_sum <- sum(st_area(FSland$geometry))

area_km <- area_sum/1000000

area_km
```

Now add that NHDPlus raster to the main raster stack and perform the masking out of wetlands and FSland. Then finally extract points from stack `thrty.34` and then combined with `pts34`. Create two different dataframes so that we can have (long, lat) and (utm's).

```{r, eval = FALSE}
#add nhd raster
topo_opt_rad34 <- addLayer(topo_opt_rad34, nhdStrOrdRast)

thrty.34 <- mask(topo_opt_rad34, wtrbdy30, inverse = TRUE) #mask out waterbodies if you want

thrty.34 <- mask(thrty.34, FSland) #mask out non-Forest Service land

thrty.34 <- raster::extract(thrty.34, pts34) #extract the values from raster by point data

top34.opt.rad <- cbind(pts34, thrty.34)

top34.opt.rad2 <- cbind(pts34, thrty.34)

#get long lat for graphing/visualizing
top34.opt.rad2 <- st_transform(top34.opt.rad2, crs = "+proj=longlat +datum=WGS84 +no_defs")

top34coords <- do.call(rbind, st_geometry(top34.opt.rad)) %>% 
    as_tibble() %>% setNames(c("utm1","utm2"))

top34lonlat <- do.call(rbind, st_geometry(top34.opt.rad2)) %>% 
    as_tibble() %>% setNames(c("lon","lat"))

st_geometry(top34.opt.rad) <- NULL

top34.opt.rad <- data.frame(cbind(top34.opt.rad,top34coords, top34lonlat))



write.csv(top34.opt.rad, file = "top34.opt.rad.csv")
```

Now clean up the data. Pre-proccessing.

```{r, eval = FALSE}
top34.opt.rad <- read.csv("top34.opt.rad.csv", header = TRUE)[-1]

data34 <- top34.opt.rad #change for ease

#change names
names(data34)[1] <- "stream"

names(data34)[19] <- "NHDPlus"

data34$stream <- factor(data34$stream)

#make NHDPlus "NA/land" areas = 0.
data34$NHDPlus[is.na(data34$NHDPlus)] <- 0

#remove any missing data after the previous step.
data34 <- na.omit(data34)

#this only takes streams less than stream order = 3
data34 <- data34 %>% filter(NHDPlus < 3)

# write csv

write.csv(data34, file = "data34.csv")

```

Now we can start looking at some of the data visually.

```{r, eval = FALSE}
data34 <- read_csv("data34.csv")[-1]

summary(data34)

data34 %>% select(Blue_med, Red_med, Green_med, NIR_med)  %>% pivot_longer(cols = everything(), names_to = "Feature", values_to = "value") %>% ggplot() + geom_boxplot(aes(value, color = Feature)) + coord_flip()



```

```{r echo=FALSE, fig.align='center'}

data34 %>% mutate(accum30 = log(accum30)) %>% select(npol30agg, accum30) %>% pivot_longer(cols = everything(), names_to = "Feature", values_to = "value") %>% ggplot() + geom_boxplot(aes(value)) + coord_flip() + facet_wrap(~Feature, scales = "free_y")






```


```{r, eval = FALSE}
data34 <- data34 %>% filter(npol30agg > -1, npol30agg < 1)
```

Now look at the new boxplot and histogram for `npol30agg`, which looks much better.

```{r echo=FALSE, fig.align='center'}
#now look at boxplot
data34 %>% select(npol30agg) %>% gather(key, value) %>% ggplot() + geom_boxplot(aes(value)) + coord_flip()
#much better
```

After visualising, we can take a deeper look and search the data frame for correlation using a certain threshold (e.g., 90%). This is possible by  `caret`'s function called `findCorrelation`. This is the cutoff threshold that @hird2017google and @lidberg2020using used.

```{r fig.align='center', eval = FALSE}

correlations34 <- cor(data34[,-c(1,19,20,21,22,23)]) #remove response and coords and NHDPlus
corrplot(correlations34, order = "hclust")

highCorr34 <- findCorrelation(correlations34, cutoff = 0.9)
highCorr34
```



There is one variable recommended to be taken out. Let's see what they are. 

```{r}
colnames(correlations34)[c(13,15,7)]
```

We ended up taking out NDWI_med instead of NDVI_med along with Blue_med and Red_med.
```{r}
data34 <- data34[, -which(names(data34) %in% c("NDWI_med", "Blue_med", "Red_med"))]

```

```{r, out.width= "70%", fig.align='center', message=FALSE}

barplot(prop.table(table(data34$stream)),
        main = "Proportion of stream occurence", 
        names.arg = c("No Stream", "Stream"), ylab = "Proportion %") 
```
```{r, eval=TRUE, echo=FALSE}
kableExtra::kable(addmargins(table(Stream = data34$stream)), caption = "Count")
kableExtra::kable(round(prop.table(table(Stream = data34$stream)),3), caption = "Proportion")
```
We ended up having a more imbalanced data set then we wanted. 

So we can downsample the higher target class. 

```{r}

data34$stream <- factor(data34$stream)

levels(data34$stream) <- c("X1", "X2")

set.seed(1234)

data34 <- downSample(data34, data34$stream)


write_csv(data34, "data34.csv", append = FALSE)
```

```{r, out.width= "70%", fig.align='center', message=FALSE}

barplot(prop.table(table(data34$stream)),
        main = "Proportion of stream occurence", 
        names.arg = c("No Stream", "Stream"), ylab = "Proportion %") 

```

Now we want to bring in our point data along with our covariates and clean up all the preprocessing we did. 
```{r}

data34 <- read_csv("data34.csv")

ptsSF34 <- st_as_sf(data34, coords = c("utm1","utm2"))

st_crs(ptsSF34) <- proj.study



topo_new34 <- dropLayer(topo_opt_rad34, c("Blue_med", "Red_med", "NDWI_med")) #covariate stack

crs(topo_new34) <- proj.study
```

Now we can figure out our 'effictive range of spatial autocorrelation' by using the function `spatialAutoRange` in `blockCV`. This is a cool function because it takes the covariates, calculates the range of autocorrelation (from $n$ sampled points), and then produces two plots showing the range of the covariates and the recommended block size for validation.  

```{r}

sac34 <- blockCV::spatialAutoRange(rasterLayer = topo_new34,
                                 sampleNumber = 5000,
                                 doParallel = TRUE,
                                 showPlots = TRUE)

```

```{r}

Spatial_Med34 <- blockCV::spatialBlock(speciesData = ptsSF34, # presence-background data
                    species = "stream",
                    rasterLayer = topo_new34,
                    k = 10,
                      theRange = 5716,
                    selection = "systematic",
                    biomod2Format = TRUE)

```

We noticed though that when doing this type of blocking strategy the standard deviation between hold outs is very high, which can lead to bias-variance issues when modeling. See below after adding k-means nearsest neighbor.  


Finally, we can do a `kmeans` with a cluster of 80. This will be our large structure attempt.

```{r}
#this is the k-means method (using a cluster of 80)
#need coordinates.
#remember to use the coordinates, that's why we've kept them!
data34 <- data34[,-21] #take out the class added when we downsampled
write_csv(data34, "data34.csv")
Mycluster80 <- kmeans(data34[,c(17,18)], (nrow(data34)/80)) 

# add the new variable back to your dataframe here
data34$spatial_cluster80 = Mycluster80$cluster

ptsSF34$spatial_cluster80 = data34$spatial_cluster80
```

now we can do a `kmeans` with a cluster of 40. This will be our small structure attempt.


```{r}
#this is the k-means method (using a cluster of 40)
#need coordinates.
#remember to use the coordinates, that's why we've kept them!

Mycluster40 <- kmeans(data34[,c(17,18)], (nrow(data34)/40)) 

# add the new variable back to your dataframe here
data34$spatial_cluster40 = Mycluster40$cluster

ptsSF34$spatial_cluster40 = data34$spatial_cluster40
```

Now add the spatial block medium.

```{r}
data34$sb_med <- Spatial_Med34$foldID
```

```{r}
write_csv(data34, "data34.csv")
```

Now you can see the clusters and check the distribution. This is completely fair to the sb_med since we haven't added the folds to the clusters. We'll do that again in the dataSplit.Rmd file.

```{r, echo=FALSE, fig.align="center"}

data34 %>% add_count(spatial_cluster40, name = "n_40") %>% add_count(spatial_cluster80, name = "n_80") %>% add_count(sb_med, name = "n_med") %>% summarise(across(starts_with("n_"), list(mean = mean, median = median, standard_deviation = sd))) %>% t()

```

